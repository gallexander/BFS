\documentclass[11pt,a4paper]{article}
\usepackage{termpaper}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings}

%opening
\title{Parallel breadth-first search}
\author{
 \authorname{Alexander Gallauner} \\
 \studentnumber{1026090} \\
 \curriculum{534} \\
 \email{e1026090@student.tuwien.ac.at}
}

\begin{document}
\maketitle
\begin{abstract}
Some years ago, to have a continuous progress of the performance of processors, it was necessary to stop trying to increase the clock rate of CPUs, and to concentrate on the development of multicore processors. But with this development another problem was raising up. The programs or rather the algorithmic problems have to be changed to get a speed up with multicore processors. It was the job of the developers to split the work from one core to many cores and to coordinate the communication between these cores. In this scientific paper I will concentrate on algorithms for searching tree or graph data structures and how to parallelize them. To make it specific, I will keep my mind on the breadth-first search, because it is easier to parallelize than the depth-first search. First I will show a sequential algorithm to solve this problem. After that my focus is on a parallel realisation of this sequential algorithm. In this chapter I will demonstrate some improvements to the parallel algorithm to reach a better speed up.
To get a feeling how good the solution is, I will populate my solution into a benchmark for supercomputers, the graph500 project. Graph500 establishes a large-scale benchmark for data-intensive supercomputer applications. There exists already a official solution of the benchmark, so I can compare the performance of Jupiter, that is the name of the distributed system of the Vienna University of Technology, one time with my own implemented benchmark, but observing the rules of the graph500 project, and another time with the official solution of the graph500 project. Another thing is that I compare Jupiter with other supercomputers, which are listed in the graph500 ranking.
\end{abstract}

\clearpage

\section{The breadth-first search - BFS}
\label{sec:breadth-first search}

\subsection{Sequential BFS}
\label{sec:sequential-bfs}

The sequential BFS (breadth-first search) algorithm isn't difficult to understand. If you have a given tree or alternatively a graph data structure, you start with a specific node. This is our root node. We can split the graph or tree into levels, each level is handled in one single iteration of the BFS. So we can say, we start with level 0 at the root node.
Then there starts the first round of the BFS. We take all nodes of the current level (that is level 0) and visit all neighbours of the nodes of the current level. All neighbours that have been visited are now the nodes of the next level (in this case it's level 1). The next step is to take all nodes of level 1 and visit all neighbours of these nodes. The BFS algorithm ends if the current level has no neighbours anymore. For better understanding the figure below shows a few iterations of the BFS algorithm.

\subsection{Parallel BFS}
\label{sec:parallel-bfs}

To make an algorithm parallel, the main problem is to split the work of the sequential algorithm into smaller pieces and assign that pieces of work to the existing cores of the system, which are in use. 
The first approach of splitting the BFS is to split the nodes of each level and every core of the system just visit the neighbours of the owned nodes. The problem with this approach is that the communication expense is pretty high, because it's necessary to split the work every round (level) of the BFS algorithm.\\
So the second approach is to divide all the existing nodes of the graph to the processors. With this approach the highest expense of communication is just at the beginning of the algorithm. After the processors just have to communicate, which node is in the current level. For instance if I have the root node at PROC 0, the whole work of level 0 is just at the processor with the number 0. But now PROC 0 has to tell the other processors, which nodes he has visited. So these processors have to prove if they have one of these visited nodes stored in their node list. If they have, it's their turn for the next level.

\section{Implementation of the BFS and some improvements}
\label{sec:implementations}

\subsection{Parallel Implementation}
\label{sec:parallel-impl}

In this section will be an implementation of the parallel BFS in MPI.	The programming language is C.\\
Because it would be too costly to type in the node data for a scale of \(2^{32}\) or higher, the first part of the program is to generate nodes. For the data generation I used a Kronecker generator. I will threat this type of generator in a separate section of this paper.

\begin{lstlisting}
generate_graph(SCALE, EDGEFACTOR, initiator, startVertex, endVertex);
\end{lstlisting}

In this line the Kronecker generator fills the \(startVertex\) and \(endVertex\) arrays with random numbers of nodes. Each pair of \(startVertex[i]\) and \(endVertex[i]\), for \( 0 < i < N, N = count of nodes \). The \(SCALE\) parameter gives the generator the size of the graph and the \(EDGEFACTOR\) the ratio of the count of the edges to the count of the nodes. The \(initiator\) is a 2x2 map, filled with probabilities, which influences the functioning of the Kronecker generator.

\begin{lstlisting}
create_node_edge_lists(nodes, edges, startVertex, endVertex, node_edge_list, count_edges_per_node);
buffer = lists_to_buffer(&buffer_size, node_edge_list, count_edges_per_node, 0, nodes-1);
\end{lstlisting}

The next step is to bring the information of edges in a more computable form. Firstly the arrays of vertexes are converted to an array of nodes, where each entry of the array points to a list of nodes, which are neighbours of this specific entry. Secondly that array of nodes, where each entry points to a list, is transformed to a buffer, where the neighbours of the node 1 are at the beginning of the buffer, then the neighbours of the node 2 follow the neighbours of node 1, and so on.
\\
...

\section{Testing the algorithm on Jupiter}
\label{sec:testing}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=15cm]{benchmark}%
	\caption{Ergebnisse auf Jupiter}%
	\label{fig:benchmark}
\end{figure}

\section{The graph500 project and my own realisation}
\label{sec:graph500}

\section{Comparing with the official solution of graph500}
\label{sec:Comparing}

\section{Ranking of Jupiter}
\label{sec:ranking}

\section{Why no parallel realisation of depth-first search?}
\label{sec:depth-first search}

\section{Summary}
\label{sec:summary}

\clearpage

\bibliographystyle{plain}
\bibliography{references}

\end{document}