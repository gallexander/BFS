\documentclass[11pt,a4paper]{article}
\usepackage{termpaper}
\usepackage[utf8]{inputenc} 
\usepackage[ngerman]{babel}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{cleveref}
\usepackage{filecontents}
\usepackage{url}
\usepackage[labelfont=bf,textfont=it]{caption}
\usepackage{courier}
\usepackage{subcaption}

\definecolor{lstcolor}{rgb}{0.95,0.95,0.95}

\lstdefinestyle{customc}{
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=\color{black}\bfseries\underbar,
	identifierstyle=,
	commentstyle=\color{white},
	stringstyle=\ttfamily,
	showstringspaces=false,
  	tabsize=2,
	mathescape=true,
	numbers=left,
	numberstyle=\tiny,
	numbersep=10pt,
	captionpos=b,
	frame=trBL,
	breaklines=true
}
\lstset{style=customc}
\renewcommand{\lstlistingname}{Algorithmus}

%opening
\title{Parallele Breitensuche}
\author{
 \authorname{Alexander Gallauner} \\
 \studentnumber{1026090} \\
 \curriculum{534} \\
 \email{alexander.gallauner@gmail.com}
}

\begin{document}
\maketitle
\begin{abstract}
In dieser Arbeit beschäftigen wir uns mit dem Parallelisieren eines bekannten Algorithmus, der Breitensuche (BFS - \textit{Breadth-First Search}). Dabei handelt es sich um einen Suchalgorithmus für Graphen, der in vielen Fragestellungen der Graphentheorie involviert ist. Wir werden uns auf die Parallelisierung dieses Verfahrens auf Rechner mit physikalisch verteiltem Speicher (DMM - \textit{distributed memory machine}) beschränken und mehrere Wege aufweisen, wie man diese Parallelisierung realisieren kann. Dies ist keine leichte Aufgabe, da parallele Abläufe in der sequentiellen Breitensuche nicht sofort ersichtlich sind und ein guter Kompromiss zwischen Speicherverbrauch und Kommunikationsaufwand zwischen Prozessoren gefunden werden muss. Es werden verschiedene Implementierungen der Parallelisierung vorgestellt und anhand verschiedener Kriterien wie Laufzeit, Speedup und Kosten analysiert. Außerdem wird erklärt, welche Voraussetzungen gelten müssen, damit eine bestimmte Implementierung überhaupt Sinn macht. Die Implementierung findet in der Programmiersprache C statt und zur Kommunikation der Prozessoren untereinander wird OpenMPI verwendet, das eine Open-Source Implementierung des Message Passing Interface Standards (MPI) bereitstellt. (Beispiel für einen erreichten Speedup)\\
Zusätzlich wird das Projekt Graph500 vorgestellt. Graph500 ist ein Benchmark für Supercomputer, die datenintensive Anwendungen ausführen. Da die Breitensuche bei groß angelegten Graphen ein ebenfalls daten- und rechenintensives Problem darstellt, steht diese Suche im Mittelpunkt des Graph500 Projektes. So wie die Implementierungen der parallelen Breitensuche wird auch unsere Implementierung des Graph500 Projektes auf dem Supercomputer Jupiter, ein Rechner der TU Wien mit physikalisch verteiltem Speicher, ausgeführt und analysiert. Innerhalb dieses Projektes wird die Leistung in der Maßeinheit TEPS (\textit{traversed edges per second}) gemessen, welche Auskunft gibt, wie viele Kanten pro Sekunde innerhalb des Graphen besucht werden und wo sich Jupiter anhand des Benchmarks in der Graph500 Rangliste der Supercomputer einordnen würde.
\end{abstract}
\clearpage
\section{Einleitung}
\label{sec:einleitung}
Graphabstraktionen spielen in vielen wissenschaftlichen aber auch alltäglichen Gebieten eine wesentliche Rolle. Viele algorithmische Probleme können auf Graphen zurückgeführt werden, aber auch umgekehrt basiert die Lösung graphentheoretischer Probleme auf Algorithmen. Das Problem der Suche nach dem kürzesten Weg zwischen zwei Orten in einem Straßennetz kann durch einen Graph abstrahiert und mit Hilfe dieses Graphs gelöst werden. Ein Algorithmus, der den kürzesten Weg in einem ungewichteten Graph findet und Thema dieser Bachelorarbeit ist, ist die Breitensuche.\\
Vor über einem halben Jahrhundert wurde der erste Algorithmus, der den Graphen im Prinzip der Breitensuche traversiert, von Moore~\cite{moore}, während er sich mit der Findung von Pfaden in Labyrinthen beschäftigte, untersucht und herausgebracht. Fast zur gleichen Zeit und unabhängig von der Arbeit von Moore untersuchte Lee~\cite{lee} den selben Algorithmus, aber in Bezug auf das Verlegen von Drähten auf einer Platine und die damit verbundene automatische Herstellung von Platinen. Bevor wir mehr auf die Breitensuche eingehen, werden wir zuerst die Eigenschaften eines Graphen genauer beschreiben und die einzelnen Bestandteile erklären und veranschaulichen.
\subsection{Graphdefinition}
Ein Graph in der Graphentheorie ist eine abstrakte Struktur, die eine Menge von Objekten und die Verbindungen zwischen diesen Objekten repräsentiert. Genauer ausgedrückt besteht ein Graph \(G = (V, E)\), wie von Drmota, Gittenberger, Karigl und Panholzer beschrieben,  aus einer endlichen Knotenmenge \(V = V(G)\) und einer endlichen Kantenmenge \(E = E(G)\). Dabei kann eine Kante gerichtet oder ungerichtet sein. Falls alle Kanten gerichtet sind, spricht man auch von einen gerichteten Graphen, andererseits von einem ungerichteten Graphen. In dieser Arbeit arbeiten wir ausschließlich mit ungerichteten Graphen, das heißt jede Kante \(e \in E(G)\) entspricht einem ungeordnetem Paar \(e = \{ v_{1},v_{2} \} = v_{1}v_{2}\) von zwei Knoten \(v_{1}, v_{2} \in V(G)\).
\begin{figure}[h]
 	\centering
	\includegraphics[width=0.5\textwidth]{graph}
 	\caption{Beispiel eines ungerichteten Graphen mit einem Startknoten und einer Schlinge.}
	\label{fig:graph}
\end{figure}
Abbildung~\ref{fig:graph} zeigt ein Beispiel für einen ungerichteten Graphen. Eingezeichnet ist bereits ein Startknoten, schwarzer Knoten, da jede Breitensuche neben dem Graphen einen Start- beziehungsweise Wurzelknoten als Eingabeparameter erwartet. Zusätzlich ist im Graphen eine Schlinge ersichtlich, es sind also auch Kanten zugelassen, bei denen Anfangsknoten gleich Endknoten sind, was innerhalb einer Implementierung der Breitensuche berücksichtigt werden muss. Außerdem kann es sein, dass der Graph nicht zusammenhängend ist und es daher keine Kante zu mindestens einem Knoten gibt. Liegt so ein Graph vor, kann es sein, dass bestimmte Knoten ausgehend vom Startknoten durch die Breitensuche nicht erreicht werden können.\\
Um die Breitensuche zu konkretisieren beziehungsweise besser beschreiben zu können, wird noch der Begriff des Weges und der Distanz zwischen zwei Knoten spezifiziert. Eine Kantenfolge \(e_{1}, e_{2}, ..., e_{k} \in E(G)\) in einem ungerichteten Graphen \(G\) heißt \textit{Weg}, wenn alle Knoten, die durch diese Kantenfolge durchlaufen werden, voneinander verschieden sind. Während die Länge des Weges mit der Anzahl der Kanten zwischen zwei Knoten gleichzusetzen ist, bezeichnet man die \textit{Distanz} zweier Knoten  als den kürzesten Weg zwischen diesen. Das Prinzip der Breitensuche impliziert nun, dass zuerst die Knoten mit der Distanz \(d\) besucht werden und erst in Folge die Knoten mit der Distanz \(d+1\). Dadurch wird der Graph durch die Breitensuche in Levels unterteilt, wobei ein \textit{Level} eine Menge von Knoten definiert, die die selbe Distanz zum Startknoten aufweisen, was in Abbildung~\ref{fig:graph_level} ersichtlich ist. Dabei kann man auch sagen, dass der Knoten die Distanz \(d\) aufweist beziehungsweise zum Level \(d\) gehört. Die größte Distanz zwischen zwei Knoten in einem Graphen \(G\) wird auch als Durchmesser \(D(G)\) (\textit{diameter}) bezeichnet.\\
\begin{figure}[h]
 	\centering
	\includegraphics[width=0.5\textwidth]{graph_level}
 	\caption{Nach der Breitensuche ist der Graph in Levels unterteilt. Dies ist ersichtlich an den Distanzen, die in den Knoten eingezeichnet sind. Der graue Knoten entspricht einem nicht besuchten Knoten.}
	\label{fig:graph_level}
\end{figure}
Ausgehend vom Startknoten wurde die Breitensuche auf den Graph von Abbildung~\ref{fig:graph} angewendet. Dadurch wird der Graph in die einzelnen Levels unterteilt, welche aus der Beschriftung der Knoten ersichtlich sind. Der grau hinterlegte Knoten entspricht einem Knoten, der durch die Breitensuche nicht erreicht wurde. Der Durchmesser ist gleich dem höchstem Level im Graphen und ist in diesem Fall \(3\).
Es ist auch möglich andere Informationen als die Distanz in Bezug auf einen Knoten abzuspeichern. Dies wird von vielen unterschiedlichen Applikationen, die die Breitensuche anwenden, erwartet beziehungsweise gefordert. Ein Beispiel dafür ist das Abspeichern des Vaterknotens für jeden besuchten Knoten, damit man am Ende der Breitensuche einen Spannbaum der besuchten Knoten liefern kann. Aus Performancezwecken und auch als Beitrag zur Einfachheit und Parallelität sollten zusätzlichen Informationen oder Berechnungen, wenn möglich, beim erstmaligen Besuchen des Knoten durchgeführt werden.
\subsection{Sequentielle Breitensuche}
Nachdem die grundlegenden Bestandteile und Eigenschaften eines Graphen geklärt sind, widmen wir uns weiters dem eigentlichen Thema dieser Arbeit, nämlich der Breitensuche. Auch wenn das Grundkonzept der Breitensuche schon erklärt wurde, zeigt Algorithmus~\ref{fifo} eine klassische sequentielle Variante von Cormen, Leiserson, Rivest und Stein \cite{cormen_introduction_2009}, welche eine Warteschlange (\textit{queue}) verwendet, die im FIFO (\textit{first in first out}) Prinzip arbeitet. Diese Variante der Implementierung gehört zu einer der einfachsten der Breitensuche.
\begin{lstlisting}[caption={Klassische Variante der Breitensuche unter Verwendung einer FIFO Warteschlange als Datenstruktur. Wird auf einem Graph \(G\) mit Startknoten \(v_{0} \in V(G)\) angewandt. Der Algorithmus bestimmt die Distanz und den Vaterknoten von denjenigen Knoten, die ausgehend vom Startknoten erreichbar sind.},label=fifo]
$\textbf{SERIAL-BFS-QUEUE}$(G,$v_{0}$)
	$\textbf{for}$ each vertex $\in$ V(G) - {$v_{0}$}
		u.d = $\infty$
		u.$\pi$ = NIL
	$v_{0}$.d = 0
	$v_{0}$.$\pi$ = NIL
	Q = {$v_{0}$}
	$\textbf{while}$ Q $\neq$ 0
		u = DEQUEUE(Q)
		$\textbf{for}$ each v $\in$ G.Adj[u]
			$\textbf{if}$ v.d == $\infty$
				v.d = u.d + 1
				v.$\pi$ = u
				ENQUEUE(Q,v)
\end{lstlisting}
Zu Beginn von Algorithmus~\ref{fifo} werden alle Knoten, die in \(V(G)\) enthalten sind, in den Zeilen 2-4 initialisiert. Ein Knoten \(u \in V\) besitzt die Attribute \lstinline{u.d} für die Distanz und \lstinline{u.$\pi$} für den Vaterknoten. Da zu Beginn noch keine Knoten besucht wurden, wird die Distanz \lstinline{u.d} auf \lstinline{$\infty$} und der Vaterknoten \lstinline{u.$\pi$} auf \lstinline{NIL} gesetzt. Das hat auch folgenden Grund, dass Knoten, die nicht durch die Breitensuche erreicht werden, keine Vaterknoten besitzen, \lstinline{u.$\pi$ = NIL}, und keine gültige Distanz, \lstinline{u.d = $\infty$}, ausgehend vom Startknoten aufweisen.\\
Zeile 5 weist dem Attribut Distanz des Startknotens den Wert 0 zu. In Zeile 6 wird der Vaterknoten des Startknotens auf \lstinline{NIL} gesetzt. In Zeile 7 und 8 wird die Warteschlange initialisiert und bekommt als erstes Element den Startknoten. Nun wird die \lstinline{$\textbf{while}$} Schleife von Zeile 8-14 solange ausgeführt, solange es Knoten gibt, die noch nicht besucht wurden, aber vom Startknoten erreichbar sind. Innerhalb der \lstinline{$\textbf{while}$} Schleife wird in Zeile 9 das Element nach dem FIFO Prinzip aus der Warteschlange genommen, das heißt das Element, das zeitlich am längsten in der Warteschlange war. Die \lstinline{$\textbf{for}$} Schleife in den Zeilen 10-14 iteriert über die Nachbarn \lstinline{v $\in$ G.Adj[u]} des aktuellen Knoten \lstinline{u}. Als Nachbar werden folgende Knoten bezeichnet, die adjazent zum jeweiligen Knoten sind, also durch eine Kante verbunden sind. In Zeile 11 wird überprüft, ob der Knoten \lstinline{v} noch nicht besucht wurde, was mittels \lstinline{$\textbf{if}$} Bedingung
\lstinline{v.d == $\infty$} geprüft wird. Ist dies der Fall, wird \lstinline{v.d} auf \lstinline{u.d + 1} gesetzt und \lstinline{u} wird als Vater in \lstinline{v.$\pi$} gekennzeichnet. Danach wird der Knoten \lstinline{u} in die Warteschlange aufgenommen. Der Algorithmus endet, wenn bei der Überprüfung der Bedingung in Zeile 8 keine Elemente in der Warteschlange vorhanden sind, was bedeutet, dass alle erreichbaren Knoten besucht wurden und die Schleife abbricht.\\
Dadurch dass jedem besuchten Knoten \lstinline{u} mit \lstinline{u.$\pi$} der Vaterknoten zugewiesen wird, entsteht durch die Breitensuche ein Subgraph von \(G\) der Vaterknoten, definiert durch \(G_{\pi} = (V_{\pi}, E_{\pi})\), wobei \(V_{\pi} = \{v \in V : v.\pi \neq\) \lstinline{NIL}\(\} \cup \{v_{0}\}\) und \(E_{\pi} = \{(v.\pi,v) : v \in V_{\pi} - \{v_{0}\}\}\). Beim Subgraph \(G_{\pi}\) handelt es sich um einen Baum (\textbf{\textit{breadth-first tree}}), der alle Knoten \(V_{\pi} \) enthält, die vom Startknoten \(v_{0}\) erreichbar sind. Da es sich um einen Baum handelt, existiert für alle Knoten \(v \in V_{\pi}\) im Subgraphen \(G_{\pi}\) genau ein Pfad von \(v_{0}\) nach \(v\), der gleichzeitig auch der kürzeste Pfad von \(v_{0}\) nach \(v\) in \(G\) ist.
\subsection{Analyse von Algorithmen}
Um Vorherzusagen, wie viele Ressourcen ein Algorithmus benötigen wird, ist die Analyse eines Algorithmus entscheidend. Dabei ist für uns die Ressource \textit{Laufzeit} maßgebend. Falls man mehrere Algorithmen zur Lösung eines Problems zur Verfügung hat, wird man sich meist für den Algorithmus mit der besten Laufzeit entscheiden.\\
Um einen Algorithmus maschinenunabhängig analysieren zu können, macht man Gebrauch vom RAM (\textit{random-access machine}) Modell. Dieses abstrakte Rechnermodell hat einen einzigen Prozessor und Instruktionenen werden sequentiell ausgeführt. Folgende Annahmen werden getroffen:
\begin{itemize}
	\item{Eine einfache Operation wird in einem Schritt ausgeführt.}
	\item{Subroutinen und Schleifen sind keine einfachen Operationen.}
	\item{Der Speicher ist unbegrenzt, ein Speicherzugriff benötigt einen Schritt.}
\end{itemize}
Die Laufzeit des Algorithmus ist nun die Anzahl der benötigten Schritte, die abhängig von der Länge \(n\) der Eingabe ist und für größer werdende \(n\) asymptotisch unter Verwendung der Landau-Notation abgeschätzt wird. Eine ausführliche und weiterführende Beschreibung der Analyse von Algorithmen ist in \cite{cormen_introduction_2009} von Cormen et al. zu finden.\\
Um nun die sequentielle Breitensuche im RAM Modell zu analysieren, ist es nun entscheidend von welchen Eingaben die Laufzeit abhängt. Es stellt sich heraus, dass die Anzahl der Knoten \(n = |V(G)|\) und der Kanten \(m = |E(G)|\) eines Graphen die Laufzeit der Breitensuche beeinflussen. Algorithmus~\ref{fifo} weist eine Laufzeit von \($O$(n + m)\) auf, da im schlimmsten Fall alle Knoten und damit auch alle Kanten besucht werden. Die Anzahl der Iterationen, Zeile 8-14, ist dabei gebunden an die Anzahl der Knoten \(|V(G)|\) und innerhalb jedes Knoten werden all seine Kanten, Zeile 10-14, angesehen. 
\section{Parallele Breitensuche}
\label{parallel}
In der Praxis ist es oft nicht ausreichend eine sequentielle Variante der Breitensuche zur Verfügung zu haben, da es sich oft um sogenannte "'big data"' Anwendungsbereiche handelt, also um Anwendungsbereiche die eine große Datenmenge zu Grunde liegen haben. Die sequentielle Variante, die auf einem einzigen Prozessor ausgeführt wird, ist einfach zu langsam für größer werdende Graphen. Daher ist es unser Ziel, einen parallelen Algorithmus für die Breitensuche zu finden, der den Graphen parallel traversiert und im Vergleich zur sequentiellen Variante einen Speedup erzielt. Der \textit{Speedup}-Begriff, wie durch Rauber und Rünger~\cite{rauber} definiert, wird als Maß für den relativen Geschwindikeitsgewinn herangezogen. Der Speedup \(S_{p}(n)\) ist definiert als
\begin{equation}
	S_{p}(n) = \frac{T^{*}(n)}{T_{p}(n)}
\end{equation}
Dabei ist \(T^{*}(n)\) die Laufzeit einer optimalen sequentiellen Implementierung und \(T_{p}(n) \) die Laufzeit eines parallelen Programmes. \(p\) steht für die Anzahl der zur Verfügung stehenden Prozessoren zur Lösung eines Problems der Größe \(n\). Es gilt \(S_{p}(n) \leq p\). Wäre \(S_{p}(n) \geq p\), könnte man einen sequentiellen Algorthmus finden, der schneller als der für die Berechnung des Speedups verwendete ist.\\
Neben der Laufzeit und des Speedups eines parallelen Programms spielt in unserer Analyse von parallelen Lösungen noch ein dritter Faktor eine wichtige Rolle, nämlich die Kosten. Die \textit{Kosten} eines parallelen Programms sind nach Rauber und Rünger \cite{rauber} definiert als
\begin{equation}
	C_{p}(n) = T_{p}(n) \cdot p
 \end{equation}
und ist die von allen Prozessoren ausgeführte Arbeit. Unser Ziel in Bezug auf die Kosten ist es, ein paralleles Programm zu finden, dass \textit{kostenoptimal} beziehungsweise annähernd kostenoptimal ist, also bei dem gilt \(C_{p}(n) = T^{*}(n)\). Das heißt es sollen vom parallelen Programm insgesamt genauso viele Operationen ausgeführt werden wie von einem optimalen sequentiellen Verfahren.
\subsection{Erste Überlegungen}
Nachdem beschrieben wurde, wie ein paralleles Programm in unserer Arbeit bewertet wird, auch in Bezug auf das sequentielle Verfahren, wenden wir uns wieder dem eigentlichen Thema zu, der Breitensuche und deren Parallelisierung. Es ist bei vielen Problemen schwierig einen sequentiellen Algorithmus mit nur wenigen Änderungen in einen parallelen umzusetzen. Oft muss man eine andere Sicht auf das zu lösende Problem bekommen und sich eine ähnliche oder andere Lösung heranziehen, bei der eine parallele Umsetzung besser möglich ist. Ein Beispiel dafür ist Algorithmus~\ref{fifo}.  Dieser Algorithmus zur Lösung der Breitensuche ist schwierig zu parallelisieren, da die FIFO Warteschlange ein Hindernis für die Parallelisierung auf Rechnern mit physikalisch verteiltem Speicher darstellt, falls man diese im parallelen Algorithmus synchronisiert halten will. Ein ausführlichere Beschreibung liefert hierbei Leiserson und Schardl~\cite{leiserson}.\\
Aus diesem Grund geben wir noch einen weiteren sequentiellen Algorithmus durch Algorithmus~\ref{stacks} an, der anstatt der FIFO Warteschlange zwei Stapelspeicher (\textit{stacks}) verwendet, wodurch ein level-basiertes Durchsuchen des Graphen, wie in Abbildung~\ref{fig:graph_level}, ersichtlicher wird. Mit Hilfe von Algorithmus~\ref{stacks} ist es einfacher, einen parallelen Algorithmus abzuleiten. Dieser Algorithmus wird auch von Buluc und Madduri~\cite{buluc} als Basis für deren Arbeit zur parallelen Breitensuche verwendet und ist auch in deren Arbeit abgebildet.
\begin{lstlisting}[caption={Eine weitere sequentielle Variante der Breitensuche unter Verwendung von zwei Stacks \lstinline{FS} und \lstinline{NS} als Datenstrukturen. Dieser Algorithmus liefert das gleiche Ergebnis wie Algorithmus~\ref{fifo} und hat auch die gleiche Laufzeit wie dieser, ermöglicht jedoch eine bessere Sicht auf das level-basierte Durchsuchen des Graphen, was das Ableiten eines parallelen Algorithmus einfacher macht.},label=stacks]
$\textbf{SERIAL-BFS-STACKS}$(G,$v_{0}$)
	$\textbf{for}$ each vertex $\in$ V(G) - {$v_{0}$}
		u.d = $\infty$
		u.$\pi$ = NIL
	$v_{0}$.d = 0
	$v_{0}$.$\pi$ = NIL
	level = 1
	FS = {$v_{0}$}
	NS = $\emptyset$
	$\textbf{while}$ FS $\neq$ 0
		$\textbf{for}$ each u $\in$ FS
			$\textbf{for}$ each v $\in$ G.Adj[u]
				$\textbf{if}$ v.d == $\infty$
					v.d = level
					v.$\pi$ = u
					NS = NS $\cup$ {v}
		FS = NS
		NS = $\emptyset$
		level = level + 1
\end{lstlisting}
Algorithmus~\ref{stacks} ist sehr ähnlich zu Algorithmus~\ref{fifo}. Es werden jedoch zwei Datenstrukturen benötigt und es gibt eine weitere verschachtelte Schleife in Zeile 11. Bei den zwei Datenstrukturen handelt es sich um \lstinline{FS} (\textit{frontier stack}), der Stapelspeicher, wo die Knoten des aktuellen Levels gespeichert sind, und \lstinline{NS} (\textit{newly-visited stack}), der Stapelspeicher, wo die neu besuchten Knoten gespeichert werden, also die Knoten, die ein um eins höheres Level haben als die Knoten in \lstinline{FS}.\\
Nach der Initialisierung wird die \lstinline{$\textbf{while}$} von Zeile 10-19 solange ausgeführt bis es keine neu besuchten Knoten im nächsten Level gibt, also keine Knoten mehr ausgehend vom Startknoten \lstinline{$v_{0}$} erreicht werden können. In den Zeilen 11-16 wird mittels \lstinline{$\textbf{for}$} Schleife über alle Knoten des aktuellen Levels iteriert. Durch die Bedingung in Zeile 10 muss zumindest ein Element \lstinline{u} in \lstinline{FS} enthalten sein. Über die Nachbarn des Knoten \lstinline{u} in Zeile 12-16 wird genauso iteriert wie in Algorithmus~\ref{fifo}, außer dass hier die Nachbarn \lstinline{v}, die zuvor noch nicht besucht wurden, also \lstinline{v.d == $\infty$}, im Stapelspeicher \lstinline{NS} abgelegt werden. Ebenfalls sehr entscheidend für diesen Algorithmus ist, dass nachdem alle Knoten des aktuellen Levels abgearbeitet wurden, der Stapelspeicher \lstinline{FS} die Elemente von \lstinline{NS} übernimmt und \lstinline{NS} geleert wird. \lstinline{FS} hat also alle Knoten nun gespeichert, die zuvor in Zeile 14-16 neu besucht wurden. Danach wird der Wert von \lstinline{level}, der den neu besuchten Knoten durch \lstinline{v.d = level} zugewiesen wird, um eins erhöht und die nächste Iteration mit den neu besuchten Knoten startet.\\
Die Laufzeit von Algorithmus~\ref{stacks} ist genauso wie bei Algorithmus~\ref{fifo} \($O$(n + m)\), wobei die Anzahl der Iterationen von der \lstinline{$\textbf{while}$} Schleife von Zeile 10-19 gebunden ist an die Länge des längsten Pfades vom Startknoten \(v_{0}\) zu einem erreichbaren Knoten im Graphen \(G\), was dem Durchmesser (\textit{diameter}) \(D\) des Subgraphen \(G_{\pi}\) entspricht.\\
Anhand dieser Überlegungen gibt es nun unterschiedliche Wege die Breitensuche zu parallelisieren. Wie schon durch Buluc und Madduri~\cite{buluc} spezifiert, gibt es zwei grundlegende Varianten, wie man dieses Problem parallelisiert, nämlich durch Zerlegung beziehungsweise Aufteilung des Graphen auf die zur Verfügung stehenden Prozessoren. Natürlich hängt diese Zerlegung auch von der Repräsentation des Graphen in der Implementierung ab, womit wir uns aber erst in Kapitel~\ref{sec:details} genauer beschäftigen werden. Vorerst ist nur die Idee der Zerlegung wichtig. Wir gehen davon aus, dass die Knoten des Graphen durchgehend nummeriert sind und dass wir mit jeder Knotennummer direkt auf die Kanten dieses Knoten zugreifen können.
\begin{itemize}
	\item{Eindimensionale (\textbf{1D}) Zerlegung des Graphen bedeutet nun, dass man die Knoten des Graphen \(V(G)\) auf die Prozessoren so aufteilt, dass wenn \(n = |V(G)|\) jeder Prozessor in Besitz von \(n / p\) Knoten ist, wobei \(p\) die Anzahl der verfügbaren Prozessoren darstellt. Zusätzlich besitzt jeder Prozessor lokal die Kanten, die mit einem auf dem Prozessor gespeicherten Knoten verbunden sind, also jede Kante \(e = \{v_{1},v_{2}\}, e \in E(G)\), wo entweder \(v_{1}\) oder \(v_{2}\) ein lokaler Knoten des Prozessors ist.}
	\item{Bei der zweidimensionalen (\textbf{2D})  Zerlegung werden nicht nur die Knoten unter den Prozessoren aufgeteilt, sondern es werden auch die zu den Knoten zugehörigen Kanten unter mehreren Prozessoren aufgeteilt. Das heißt es kann sein, dass mehrere Prozessoren die gleiche Knotenmenge besitzen, jedoch unterschiedliche Kanten zu diesen Knoten.}
\end{itemize}
Diese Zerlegungen lassen sich sehr gut mit einer Adjazenzmatrix darstellen, es ist jedoch nicht notwendig auch eine Matrix als Graphrepräsentation in der Implementierung zu verwenden, diese Repräsentation soll nur zum Verständnis beitragen.
\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=0.9\textwidth]{eindim}
        \caption{eindimensional}
        \label{fig:eindim}
    \end{subfigure}
   \qquad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=0.9\textwidth]{zweidim}
        \caption{zweidimensional}
        \label{fig:zweidim}
    \end{subfigure}
    \caption{Es ist möglich, den Graphen ein- oder zweidimensional zu zerlegen. Diese abstrakte Darstellung einer Adjazenzmatrix in Abbildung~\ref{fig:eindim} zeigt, dass im eindimensionalen Fall die Zerlegung nur auf einer Achse erfolgt, im zweidimensionalen Fall in Abbildung~\ref{fig:zweidim} auf zwei Achsen.}
\label{fig:zerlegung}
\end{figure}
Abbildung~\ref{fig:zerlegung} zeigt die Zerlegung des Graphen im ein- und zweidimensionalen Fall. Repräsentiert wird der Graph durch eine Adjazenzmatrix. Das heißt, dass auf beiden Achsen die Knoten eingetragen sind und jeder Eintrag in der Matrix die Information speichert, ob eine Kante zwischen diesen Knoten existiert oder nicht.  Im eindimensionalen Fall heißt das, dass die Knoten, die auf der horizontalen Achse eingetragen sind, und alle zugehörigen Kanten, dargestellt durch die Spalten in der Matrix, unter den Prozessoren aufgeteilt werden. Ein Rahmen (\textit{frame}) spiegelt also wider, was in einem Prozessor abgespeichert wird. Im Gegensatz dazu wird bei der zweidimensionalen Zerlegung auch die vertikale Achse auf mehrere Prozessoren aufgeteilt, wodurch es, wie schon weiter oben erwähnt, der Fall ist, dass sich mehrere Prozessoren die gleiche Knotenmenge teilen, aber unterschiedliche Kanten zu diesen Knoten abspeichern beziehungsweise behandeln.\\
Ausgehend von der level-basierten sequentiellen Breitensuche, dargestellt durch Algorithmus~\ref{stacks}, und der eindimensionalen Zerlegung des Graphen, werden wir zwei Algorithmen zur parallelen Breitensuche abstrakt veranschaulichen. Grundlegender Unterschied dieser zwei Algorithmen ist die Synchronisation zwischen den Prozessoren, also welche Daten werden wie synchronisiert. Außerdem liegen Unterschiede darin, wieviel die Prozessoren über den Gesamtzustand des Systems wissen, also zum Beispiel ob Knoten, die anderen Prozessoren zugeordnet sind, bereits besucht wurden und deshalb im nächsten Level nicht mehr berücksichtigt werden müssen. Wichtig ist jedoch, dass beide Algorithmen mit einer 1D Zerlegung des Graphen arbeiten. Details über die Implementierung und welche Auswirkungen diese Unterschiede auf die Laufzeit des Algorithmus haben, sind in Kapitel~\ref{sec:details} beziehungsweise Kapitel~\ref{sec:analyse} zu finden.
\subsection{BFS mit Allreduce Kommunikation}
\label{sec:bfs_alltoall}
\subsection{BFS mit All-to-all Kommunikation}
\label{sec:bfs_alltoall}
\section{Implementierungsdetails}
\label{sec:details}
\section{Analyse der Algorithmen und Versuchsergebnisse}
\label{sec:analyse}

\clearpage

\bibliographystyle{abbrv}
\bibliography{bachelor}
\clearpage
\appendix
\section{BFS versions}
\label{sec:versions}
\lstinputlisting[firstline=138,lastline=196,caption={Version 1 - level bitmap},label=version1]{../Source/bfs_par.c}
\lstinputlisting[firstline=135,lastline=183,caption={Version 2 - level array},label=version2]{../Source/bfs_par_parentarray.c}
\lstinputlisting[firstline=153,lastline=205,caption={Version 3 - visited bitmap},label=version3]{../Source/bfs_par_allvisited_parallelsort.c}
\section{Source Code - graph500}
\label{sec:sourcecode}
\lstinputlisting[caption={BFS solution},label=bfs]{../Source/bfs_par_allvisited_parallelsort.c}
\clearpage
\lstinputlisting[caption={Kronecker Generator},label=kronecker_generator]{../Source/kronecker_generator.c}
\clearpage
\lstinputlisting[caption={project.h},label=project]{../Source/project.h}

\clearpage


\end{document}