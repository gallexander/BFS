\documentclass[11pt,a4paper]{article}
\usepackage{termpaper}
\usepackage[utf8]{inputenc} 
\usepackage[ngerman]{babel}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{cleveref}
\usepackage{filecontents}
\usepackage{url}
\usepackage[labelfont=bf,textfont=it]{caption}
\usepackage{courier}
\usepackage{subcaption}

\definecolor{lstcolor}{rgb}{0.95,0.95,0.95}

\lstdefinestyle{customc}{
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=\color{black}\bfseries\underbar,
	identifierstyle=,
	commentstyle=\color{white},
	stringstyle=\ttfamily,
	showstringspaces=false,
  	tabsize=2,
	mathescape=true,
	numbers=left,
	numberstyle=\tiny,
	numbersep=10pt,
	captionpos=b,
	frame=trBL,
	breaklines=true
}
\lstset{style=customc}
\renewcommand{\lstlistingname}{Algorithmus}

%opening
\title{Parallele Breitensuche}
\author{
 \authorname{Alexander Gallauner} \\
 \studentnumber{1026090} \\
 \curriculum{534} \\
 \email{alexander.gallauner@gmail.com}
}

\begin{document}
\maketitle
\begin{abstract}
In dieser Arbeit beschäftigen wir uns mit dem Parallelisieren eines bekannten Algorithmus, der Breitensuche (BFS - \textit{Breadth-First Search}). Dabei handelt es sich um einen Suchalgorithmus für Graphen, der in vielen Fragestellungen der Graphentheorie involviert ist. Wir werden uns auf die Parallelisierung dieses Verfahrens auf Rechner mit physikalisch verteiltem Speicher (DMM - \textit{distributed memory machine}) beschränken und mehrere Wege aufweisen, wie man diese Parallelisierung realisieren kann. Dies ist keine leichte Aufgabe, da parallele Abläufe in der sequentiellen Breitensuche nicht sofort ersichtlich sind und ein guter Kompromiss zwischen Speicherverbrauch und Kommunikationsaufwand zwischen Prozessoren gefunden werden muss. Es werden verschiedene parallele Algorithmen vorgestellt und die Implementierungen dieser Algorithmen anhand verschiedener Kriterien wie Laufzeit, Speedup und Kosten analysiert. Außerdem wird erklärt, welche Voraussetzungen gelten müssen, damit ein bestimmter Algorithmus überhaupt Sinn macht. Die Implementierung findet in der Programmiersprache C statt und zur Kommunikation der Prozessoren beziehungsweise der Knoten wird OpenMPI verwendet, das eine Open-Source Implementierung des Message Passing Interface Standards (MPI) bereitstellt. Um die Kommunikation zwischen den Knoten einer  DMM zu reduzieren, haben wir auch einen sogenannten Hybrid-Algorithmus entwickelt. Die Implementierung dieses Hybrid-Algorithmus verwendet eine Kombination aus MPI und OpenMP, wobei OpenMP eine Programmierschnittstelle für die Programmierung von Parallelrechnern mit gemeinsamen Adressraum darstellt. (Beispiel Speedup)\\
Zusätzlich wird das Projekt Graph500 vorgestellt. Graph500 ist ein Benchmark für Supercomputer, die datenintensive Anwendungen ausführen. Da die Breitensuche bei groß angelegten Graphen ein ebenfalls daten- und rechenintensives Problem darstellt, steht diese Suche im Mittelpunkt des Graph500 Projektes. So wie die Implementierungen der parallelen Breitensuche wird auch unsere Implementierung des Graph500 Projektes auf dem Supercomputer Jupiter, ein Rechner der TU Wien mit physikalisch verteiltem Speicher, ausgeführt und analysiert. Innerhalb dieses Projektes wird die Leistung in der Maßeinheit TEPS (\textit{traversed edges per second}) gemessen, welche Auskunft gibt, wie viele Kanten pro Sekunde innerhalb des Graphen besucht werden und wo sich Jupiter anhand des Benchmarks in der Graph500 Rangliste der Supercomputer einordnen würde.
\end{abstract}
\clearpage
\section{Einleitung}
\label{sec:einleitung}
Graphabstraktionen spielen in vielen wissenschaftlichen aber auch alltäglichen Gebieten eine wesentliche Rolle. Viele algorithmische Probleme können auf Graphen zurückgeführt werden, aber auch umgekehrt basiert die Lösung graphentheoretischer Probleme auf Algorithmen. Das Problem der Suche nach dem kürzesten Weg zwischen zwei Orten in einem Straßennetz kann durch einen Graph abstrahiert und mit Hilfe dieses Graphs gelöst werden. Ein Algorithmus, der den kürzesten Weg in einem ungewichteten Graph findet und Thema dieser Bachelorarbeit ist, ist die Breitensuche.\\
Vor über einem halben Jahrhundert wurde der erste Algorithmus, der den Graphen im Prinzip der Breitensuche traversiert, von Moore~\cite{moore}, während er sich mit der Findung von Pfaden in Labyrinthen beschäftigte, untersucht und herausgebracht. Fast zur gleichen Zeit und unabhängig von der Arbeit von Moore untersuchte Lee~\cite{lee} den selben Algorithmus, aber in Bezug auf das Verlegen von Drähten auf einer Platine und die damit verbundene automatische Herstellung von Platinen. Bevor wir mehr auf die Breitensuche eingehen, werden wir zuerst die Eigenschaften eines Graphen genauer beschreiben und die einzelnen Bestandteile erklären und veranschaulichen.
\subsection{Graphdefinition}
Ein Graph in der Graphentheorie ist eine abstrakte Struktur, die eine Menge von Objekten und die Verbindungen zwischen diesen Objekten repräsentiert. Genauer ausgedrückt besteht ein Graph \(G = (V, E)\), wie von Drmota, Gittenberger, Karigl und Panholzer beschrieben,  aus einer endlichen Knotenmenge \(V = V(G)\) und einer endlichen Kantenmenge \(E = E(G)\). Dabei kann eine Kante gerichtet oder ungerichtet sein. Falls alle Kanten gerichtet sind, spricht man auch von einen gerichteten Graphen, andererseits von einem ungerichteten Graphen. In dieser Arbeit arbeiten wir ausschließlich mit ungerichteten Graphen, das heißt jede Kante \(e \in E(G)\) entspricht einem ungeordnetem Paar \(e = \{ v_{1},v_{2} \} = v_{1}v_{2}\) von zwei Knoten \(v_{1}, v_{2} \in V(G)\).
\begin{figure}[h]
 	\centering
	\includegraphics[width=0.5\textwidth]{graph}
 	\caption{Beispiel eines ungerichteten Graphen mit einem Startknoten und einer Schlinge.}
	\label{fig:graph}
\end{figure}
Abbildung~\ref{fig:graph} zeigt ein Beispiel für einen ungerichteten Graphen. Eingezeichnet ist bereits ein Startknoten, schwarzer Knoten, da jede Breitensuche neben dem Graphen einen Start- beziehungsweise Wurzelknoten als Eingabeparameter erwartet. Zusätzlich ist im Graphen eine Schlinge ersichtlich, es sind also auch Kanten zugelassen, bei denen Anfangsknoten gleich Endknoten sind, was innerhalb einer Implementierung der Breitensuche berücksichtigt werden muss. Außerdem kann es sein, dass der Graph nicht zusammenhängend ist und es daher keine Kante zu mindestens einem Knoten gibt. Liegt so ein Graph vor, kann es sein, dass bestimmte Knoten ausgehend vom Startknoten durch die Breitensuche nicht erreicht werden können.\\
Um die Breitensuche zu konkretisieren beziehungsweise besser beschreiben zu können, wird noch der Begriff des Weges und der Distanz zwischen zwei Knoten spezifiziert. Eine Kantenfolge \(e_{1}, e_{2}, ..., e_{k} \in E(G)\) in einem ungerichteten Graphen \(G\) heißt \textit{Weg}, wenn alle Knoten, die durch diese Kantenfolge durchlaufen werden, voneinander verschieden sind. Während die Länge des Weges mit der Anzahl der Kanten zwischen zwei Knoten gleichzusetzen ist, bezeichnet man die \textit{Distanz} zweier Knoten  als den kürzesten Weg zwischen diesen. Das Prinzip der Breitensuche impliziert nun, dass zuerst die Knoten mit der Distanz \(d\) besucht werden und erst in Folge die Knoten mit der Distanz \(d+1\). Dadurch wird der Graph durch die Breitensuche in Levels unterteilt, wobei ein \textit{Level} eine Menge von Knoten definiert, die die selbe Distanz zum Startknoten aufweisen, was in Abbildung~\ref{fig:graph_level} ersichtlich ist. Dabei kann man auch sagen, dass der Knoten die Distanz \(d\) aufweist beziehungsweise zum Level \(d\) gehört. Die größte Distanz zwischen zwei Knoten in einem Graphen \(G\) wird auch als Durchmesser \(D(G)\) (\textit{diameter}) bezeichnet.\\
\begin{figure}[h]
 	\centering
	\includegraphics[width=0.5\textwidth]{graph_level}
 	\caption{Nach der Breitensuche ist der Graph in Levels unterteilt. Dies ist ersichtlich an den Distanzen, die in den Knoten eingezeichnet sind. Der graue Knoten entspricht einem nicht besuchten Knoten.}
	\label{fig:graph_level}
\end{figure}
Ausgehend vom Startknoten wurde die Breitensuche auf den Graph von Abbildung~\ref{fig:graph} angewendet. Dadurch wird der Graph in die einzelnen Levels unterteilt, welche aus der Beschriftung der Knoten ersichtlich sind. Der grau hinterlegte Knoten entspricht einem Knoten, der durch die Breitensuche nicht erreicht wurde. Der Durchmesser ist gleich dem höchstem Level im Graphen und ist in diesem Fall \(3\).
Es ist auch möglich andere Informationen als die Distanz in Bezug auf einen Knoten abzuspeichern. Dies wird von vielen unterschiedlichen Applikationen, die die Breitensuche anwenden, erwartet beziehungsweise gefordert. Für unsere Implementierungen ist es Voraussetzung, dass der Vaterknoten für jeden besuchten Knoten abgespeichert wird, damit man am Ende der Breitensuche einen Spannbaum der besuchten Knoten liefern kann. Diese Voraussetzung hat auch unsere Implementierungen stark beeinflusst, da es das Problem der Breitensuche, im Speziellen für den parallelen Fall, aufwendiger macht. Aus Performancezwecken und auch als Beitrag zur Einfachheit und Parallelität sollten zusätzlichen Informationen oder Berechnungen, wenn möglich, beim erstmaligen Besuchen des Knoten durchgeführt werden.
\subsection{Sequentielle Breitensuche}
Nachdem die grundlegenden Bestandteile und Eigenschaften eines Graphen geklärt sind, widmen wir uns weiters dem eigentlichen Thema dieser Arbeit, nämlich der Breitensuche. Auch wenn das Grundkonzept der Breitensuche schon erklärt wurde, zeigt Algorithmus~\ref{fifo} eine klassische sequentielle Variante von Cormen, Leiserson, Rivest und Stein \cite{cormen_introduction_2009}, welche eine Warteschlange (\textit{queue}) verwendet, die im FIFO (\textit{first in first out}) Prinzip arbeitet. Diese Variante der Implementierung gehört zu einer der einfachsten der Breitensuche.
\begin{lstlisting}[caption={Klassische Variante der Breitensuche unter Verwendung einer FIFO Warteschlange als Datenstruktur. Wird auf einem Graph \(G\) mit Startknoten \(v_{0} \in V(G)\) angewandt. Der Algorithmus bestimmt die Distanz und den Vaterknoten von denjenigen Knoten, die ausgehend vom Startknoten erreichbar sind.},label=fifo]
$\textbf{SERIAL-BFS-QUEUE}$(G,$s$)
	$\textbf{for}$ each vertex u $\in$ V(G) - {$s$}
		u.d = $\infty$
		u.$\pi$ = NIL
	$s$.d = 0
	$s$.$\pi$ = s
	Q = {$s$}
	$\textbf{while}$ Q $\neq$ 0
		u = DEQUEUE(Q)
		$\textbf{for}$ each v $\in$ G.Adj[u]
			$\textbf{if}$ v.d == $\infty$
				v.d = u.d + 1
				v.$\pi$ = u
				ENQUEUE(Q,v)
\end{lstlisting}
Zu Beginn von Algorithmus~\ref{fifo} werden alle Knoten, die in \(V(G)\) enthalten sind, in den Zeilen 2-4 initialisiert. Ein Knoten \(u \in V\) besitzt die Attribute \lstinline{u.d} für die Distanz und \lstinline{u.$\pi$} für den Vaterknoten. Da zu Beginn noch keine Knoten besucht wurden, wird die Distanz \lstinline{u.d} auf \lstinline{$\infty$} und der Vaterknoten \lstinline{u.$\pi$} auf \lstinline{NIL} gesetzt. Das hat auch folgenden Grund, dass Knoten, die nicht durch die Breitensuche erreicht werden, keine Vaterknoten besitzen, \lstinline{u.$\pi$ = NIL}, und keine gültige Distanz, \lstinline{u.d = $\infty$}, ausgehend vom Startknoten aufweisen.\\
Zeile 5 weist dem Attribut Distanz des Startknotens \(s\) den Wert 0 zu. In Zeile 6 wird der Vaterknoten des Startknotens auf sich selbst gesetzt. In Zeile 7 wird die Warteschlange initialisiert und bekommt als erstes Element den Startknoten. Nun wird die \lstinline{$\textbf{while}$} Schleife von Zeile 8-14 solange ausgeführt, solange es Knoten gibt, die noch nicht besucht wurden, aber vom Startknoten erreichbar sind. Innerhalb der \lstinline{$\textbf{while}$} Schleife wird in Zeile 9 das Element nach dem FIFO Prinzip aus der Warteschlange genommen, das heißt das Element, das zeitlich am längsten in der Warteschlange war. Die \lstinline{$\textbf{for}$} Schleife in den Zeilen 10-14 iteriert über die Nachbarn \lstinline{v $\in$ G.Adj[u]} des aktuellen Knoten \lstinline{u}. Als Nachbar werden folgende Knoten bezeichnet, die adjazent zum jeweiligen Knoten sind, also durch eine Kante verbunden sind. In Zeile 11 wird überprüft, ob der Knoten \lstinline{v} noch nicht besucht wurde, was mittels \lstinline{$\textbf{if}$} Bedingung
\lstinline{v.d == $\infty$} geprüft wird. Ist dies der Fall, wird \lstinline{v.d} auf \lstinline{u.d + 1} gesetzt und \lstinline{u} wird als Vater in \lstinline{v.$\pi$} gekennzeichnet. Danach wird der Knoten \lstinline{u} in die Warteschlange aufgenommen. Der Algorithmus endet, wenn bei der Überprüfung der Bedingung in Zeile 8 keine Elemente in der Warteschlange vorhanden sind, was bedeutet, dass alle erreichbaren Knoten besucht wurden und die Schleife abbricht.\\
Dadurch dass jedem besuchten Knoten \lstinline{u} mit \lstinline{u.$\pi$} der Vaterknoten zugewiesen wird, entsteht durch die Breitensuche ein Subgraph von \(G\) der Vaterknoten, definiert durch \(G_{\pi} = (V_{\pi}, E_{\pi})\), wobei \(V_{\pi} = \{v \in V : v.\pi \neq\) \lstinline{NIL}\(\}\) und \(E_{\pi} = \{\{v.\pi,v\} : v \in V_{\pi} - \{v_{0}\}\}\). Beim Subgraph \(G_{\pi}\) handelt es sich um einen Baum (\textbf{\textit{breadth-first tree}}), der alle Knoten \(V_{\pi} \) enthält, die vom Startknoten \(v_{0}\) erreichbar sind. Da es sich um einen Baum handelt, existiert für alle Knoten \(v \in V_{\pi}\) im Subgraphen \(G_{\pi}\) genau ein Pfad von \(v_{0}\) nach \(v\), der gleichzeitig auch der kürzeste Pfad von \(v_{0}\) nach \(v\) in \(G\) ist.
\subsection{Analyse von Algorithmen}
Um Vorherzusagen, wie viele Ressourcen ein Algorithmus benötigen wird, ist die Analyse eines Algorithmus entscheidend. Dabei ist für uns die Ressource \textit{Laufzeit} maßgebend. Falls man mehrere Algorithmen zur Lösung eines Problems zur Verfügung hat, wird man sich meist für den Algorithmus mit der besten Laufzeit entscheiden.\\
Um einen Algorithmus maschinenunabhängig analysieren zu können, macht man Gebrauch vom RAM (\textit{random-access machine}) Modell. Dieses abstrakte Rechnermodell hat einen einzigen Prozessor und Instruktionenen werden sequentiell ausgeführt. Folgende Annahmen werden getroffen:
\begin{itemize}
	\item{Eine einfache Operation wird in einem Schritt ausgeführt.}
	\item{Subroutinen und Schleifen sind keine einfachen Operationen.}
	\item{Der Speicher ist unbegrenzt, ein Speicherzugriff benötigt einen Schritt.}
\end{itemize}
Die Laufzeit des Algorithmus ist nun die Anzahl der benötigten Schritte, die abhängig von der Länge \(n\) der Eingabe ist und für größer werdende \(n\) asymptotisch unter Verwendung der Landau-Notation abgeschätzt wird. Eine ausführliche und weiterführende Beschreibung der Analyse von Algorithmen ist in \cite{cormen_introduction_2009} von Cormen et al. zu finden.\\
Um die sequentielle Breitensuche im RAM Modell zu analysieren, ist es nun entscheidend von welchen Eingaben die Laufzeit abhängt. Es stellt sich heraus, dass die Anzahl der Knoten \(n = |V(G)|\) und der Kanten \(m = |E(G)|\) eines Graphen die Laufzeit der Breitensuche beeinflussen. Algorithmus~\ref{fifo} weist eine Laufzeit von \($O$(n + m)\) auf, da im schlimmsten Fall alle Knoten und damit auch alle Kanten besucht werden. Die Anzahl der Iterationen, Zeile 8-14, ist dabei gebunden an die Anzahl der Knoten \(|V(G)|\) und innerhalb jedes Knoten werden all seine Kanten, Zeile 10-14, angesehen. 
\section{Parallele Breitensuche}
\label{parallel}
In der Praxis ist es oft nicht ausreichend eine sequentielle Variante der Breitensuche zur Verfügung zu haben, da es sich oft um sogenannte "'big data"' Anwendungsbereiche handelt, also um Anwendungsbereiche die eine große Datenmenge zu Grunde liegen haben. Die sequentielle Variante, die auf einem einzigen Prozessor ausgeführt wird, ist einfach zu langsam für größer werdende Graphen. Daher ist es unser Ziel, einen parallelen Algorithmus für die Breitensuche zu finden, der den Graphen parallel traversiert und im Vergleich zur sequentiellen Variante einen Speedup erzielt. Der \textit{Speedup}-Begriff, wie durch Rauber und Rünger~\cite{rauber} definiert, wird als Maß für den relativen Geschwindikeitsgewinn herangezogen. Der Speedup \(S_{p}(n)\) ist definiert als
\begin{equation}
	S_{p}(n) = \frac{T^{*}(n)}{T_{p}(n)}
\end{equation}
Dabei ist \(T^{*}(n)\) die Laufzeit einer optimalen sequentiellen Implementierung und \(T_{p}(n) \) die Laufzeit eines parallelen Programmes. \(p\) steht für die Anzahl der zur Verfügung stehenden Prozessoren zur Lösung eines Problems der Größe \(n\). Es gilt \(S_{p}(n) \leq p\). Wäre \(S_{p}(n) \geq p\), könnte man einen sequentiellen Algorthmus finden, der schneller als der für die Berechnung des Speedups verwendete ist.\\
Neben der Laufzeit und des Speedups eines parallelen Programms spielt in unserer Analyse von parallelen Lösungen noch ein dritter Faktor eine wichtige Rolle, nämlich die Kosten. Die \textit{Kosten} eines parallelen Programms sind nach Rauber und Rünger \cite{rauber} definiert als
\begin{equation}
	C_{p}(n) = T_{p}(n) \cdot p
 \end{equation}
und ist die von allen Prozessoren ausgeführte Arbeit. Unser Ziel in Bezug auf die Kosten ist es, ein paralleles Programm zu finden, dass \textit{kostenoptimal} beziehungsweise annähernd kostenoptimal ist, also bei dem gilt \(C_{p}(n) = T^{*}(n)\). Das heißt es sollen vom parallelen Programm insgesamt genauso viele Operationen ausgeführt werden wie von einem optimalen sequentiellen Verfahren.
\subsection{Erste Überlegungen}
Nachdem beschrieben wurde, wie ein paralleles Programm in unserer Arbeit bewertet wird, auch in Bezug auf das sequentielle Verfahren, wenden wir uns wieder dem eigentlichen Thema zu, der Breitensuche und deren Parallelisierung. Es ist bei vielen Problemen schwierig einen sequentiellen Algorithmus mit nur wenigen Änderungen in einen parallelen umzusetzen. Oft muss man eine andere Sicht auf das zu lösende Problem bekommen und eine ähnliche oder andere Lösung heranziehen, bei der eine parallele Umsetzung besser möglich ist. Ein Beispiel dafür ist Algorithmus~\ref{fifo}.  Dieser Algorithmus zur Lösung der Breitensuche ist schwierig zu parallelisieren, da die FIFO Warteschlange ein Hindernis für die Parallelisierung auf Rechnern mit physikalisch verteiltem Speicher darstellt, falls man diese im parallelen Algorithmus synchronisiert halten will. Ein ausführlichere Beschreibung liefert hierbei Leiserson und Schardl~\cite{leiserson}.\\
Aus diesem Grund geben wir noch einen weiteren sequentiellen Algorithmus durch Algorithmus~\ref{stacks} an, der anstatt der FIFO Warteschlange zwei Stapelspeicher (\textit{stacks}) verwendet, wodurch ein level-basiertes Durchsuchen des Graphen, wie in Abbildung~\ref{fig:graph_level}, ersichtlicher wird. Mit Hilfe von Algorithmus~\ref{stacks} ist es einfacher, einen parallelen Algorithmus abzuleiten. Dieser Algorithmus wird auch von Buluc und Madduri~\cite{buluc} als Basis für deren Arbeit zur parallelen Breitensuche verwendet und ist auch in deren Arbeit abgebildet.
\begin{lstlisting}[caption={Eine weitere sequentielle Variante der Breitensuche unter Verwendung von zwei Stacks \lstinline{FS} und \lstinline{NS} als Datenstrukturen. Dieser Algorithmus liefert das gleiche Ergebnis wie Algorithmus~\ref{fifo} und hat auch die gleiche Laufzeit wie dieser, ermöglicht jedoch eine bessere Sicht auf das level-basierte Durchsuchen des Graphen, was das Ableiten eines parallelen Algorithmus einfacher macht.},label=stacks]
$\textbf{SERIAL-BFS-STACKS}$(G,$s$)
	$\textbf{for}$ each vertex u $\in$ V(G) - {$s$}
		d[u] = $\infty$
		$\pi$[u] = NIL
	d[s] = 0
	$\pi$[s] = s
	level = 1
	FS = {s}
	NS = $\emptyset$
	$\textbf{while}$ FS $\neq$ 0
		$\textbf{for}$ each u $\in$ FS
			$\textbf{for}$ each v $\in$ G.Adj[u]
				$\textbf{if}$ d[v] == $\infty$
					d[v] = level
					$\pi$[v] = u
					NS = NS $\cup$ {v}
		FS = NS
		NS = $\emptyset$
		level = level + 1
\end{lstlisting}
Algorithmus~\ref{stacks} ist sehr ähnlich zu Algorithmus~\ref{fifo}. Es werden jedoch zwei Datenstrukturen zur Durchsuchung des Graphen benötigt und es gibt eine weitere verschachtelte Schleife in Zeile 11. Bei den zwei Datenstrukturen handelt es sich um \lstinline{FS} (\textit{frontier stack}), der Stapelspeicher, wo die Knoten des aktuellen Levels gespeichert sind, und \lstinline{NS} (\textit{newly-visited stack}), der Stapelspeicher, wo die neu besuchten Knoten gespeichert werden, also die Knoten, die ein um eins höheres Level haben als die Knoten in \lstinline{FS}. Einen Unterschied gibt es auch in der Abspeicherung der Distanz \(d\) und des Vaterknotens \(\pi\) zu jedem Knoten. Im Gegensatz zu Algorithmus~\ref{fifo} werden diese Informationen nicht direkt beim Knoten über ein Attribut abgespeichert, sondern in einer eigenen Datenstruktur \lstinline{d[1..n]} und \lstinline{$\pi$[1..n]}. In diesem Fall handelt es sich um Arrays der Länge \lstinline{n}, wobei es sich bei \lstinline{n} um die Anzahl der Knoten handelt.\\
Nach der Initialisierung wird die \lstinline{$\textbf{while}$} von Zeile 10-19 solange ausgeführt bis es keine neu besuchten Knoten gibt, also keine weiteren Knoten ausgehend vom Startknoten \lstinline{$v_{0}$} erreicht werden können. In den Zeilen 11-16 wird mittels \lstinline{$\textbf{for}$} Schleife über alle Knoten des aktuellen Levels iteriert. Durch die Bedingung in Zeile 10 muss zumindest ein Element \lstinline{u} in \lstinline{FS} enthalten sein. Über die Nachbarn des Knoten \lstinline{u} in Zeile 12-16 wird genauso iteriert wie in Algorithmus~\ref{fifo}, außer dass hier die Nachbarn \lstinline{v}, die zuvor noch nicht besucht wurden, also \lstinline{d[v] == $\infty$}, im Stapelspeicher \lstinline{NS} abgelegt werden. Ebenfalls sehr entscheidend für diesen Algorithmus ist, dass nachdem alle Knoten des aktuellen Levels abgearbeitet wurden, der Stapelspeicher \lstinline{FS} die Elemente von \lstinline{NS} übernimmt und \lstinline{NS} geleert wird. \lstinline{FS} hat also alle Knoten nun gespeichert, die zuvor in Zeile 14-16 neu besucht wurden. Danach wird der Wert von \lstinline{level}, der den neu besuchten Knoten durch \lstinline{d[v] = level} in Zeile 14 zugewiesen wird, um eins erhöht und die nächste Iteration mit den neu besuchten Knoten startet.\\
Als Ausgabe erhalten wir genauso wie bei Algorithmus~\ref{fifo} einen \textit{breadth-first tree}. Die Laufzeit von Algorithmus~\ref{stacks} ist genauso wie bei Algorithmus~\ref{fifo} \($O$(n + m)\), wobei die Anzahl der Iterationen von der \lstinline{$\textbf{while}$} Schleife von Zeile 10-19 gebunden ist an die Länge des längsten Pfades vom Startknoten \(s\) zu einem erreichbaren Knoten im Graphen \(G\), was dem Durchmesser (\textit{diameter}) \(D\) des Subgraphen \(G_{\pi}\) entspricht.\\
Anhand dieser Überlegungen gibt es nun unterschiedliche Wege die Breitensuche zu parallelisieren. Wie schon durch Buluc und Madduri~\cite{buluc} spezifiert, gibt es zwei grundlegende Varianten, wie man dieses Problem parallelisiert, nämlich durch Zerlegung beziehungsweise Aufteilung des Graphen auf die zur Verfügung stehenden Prozessoren. Natürlich hängt diese Zerlegung auch von der Repräsentation des Graphen in der Implementierung ab, womit wir uns aber erst in Kapitel~\ref{sec:details} genauer beschäftigen werden. Vorerst ist nur die Idee der Zerlegung wichtig. Wir gehen davon aus, dass die Knoten des Graphen durchgehend nummeriert sind und dass wir mit jeder Knotennummer direkt auf die Kanten dieses Knoten zugreifen können.
\begin{itemize}
	\item{Eindimensionale (\textbf{1D}) Zerlegung des Graphen bedeutet nun, dass man die Knoten des Graphen \(V(G)\) auf die Prozessoren so aufteilt, dass wenn \(n = |V(G)|\) jeder Prozessor in Besitz von \(n / p\) Knoten ist, wobei \(p\) die Anzahl der verfügbaren Prozessoren darstellt. Zusätzlich besitzt jeder Prozessor lokal die Kanten, die mit einem auf dem Prozessor gespeicherten Knoten verbunden sind, also jede Kante \(e = \{v_{1},v_{2}\}, e \in E(G)\), wo entweder \(v_{1}\) oder \(v_{2}\) ein lokaler Knoten des Prozessors ist, da es sich um einen ungerichteten Graphen handelt.}
	\item{Bei der zweidimensionalen (\textbf{2D})  Zerlegung werden nicht nur die Knoten unter den Prozessoren aufgeteilt, sondern es werden auch die zu den Knoten zugehörigen Kanten unter mehreren Prozessoren aufgeteilt. Das heißt es kann sein, dass mehrere Prozessoren die gleiche Knotenmenge besitzen, jedoch unterschiedliche Kanten zu diesen Knoten.}
\end{itemize}
Diese Zerlegungen lassen sich sehr gut mit einer Adjazenzmatrix darstellen, es ist jedoch nicht notwendig auch eine Matrix als Graphrepräsentation in der Implementierung zu verwenden, diese Repräsentation soll nur zum Verständnis beitragen.
\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=0.9\textwidth]{eindim}
        \caption{eindimensional}
        \label{fig:eindim}
    \end{subfigure}
   \qquad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=0.9\textwidth]{zweidim}
        \caption{zweidimensional}
        \label{fig:zweidim}
    \end{subfigure}
    \caption{Es ist möglich, den Graphen ein- oder zweidimensional zu zerlegen. Diese abstrakte Darstellung einer Adjazenzmatrix in Abbildung~\ref{fig:eindim} zeigt, dass im eindimensionalen Fall die Zerlegung nur auf einer Achse erfolgt, im zweidimensionalen Fall in Abbildung~\ref{fig:zweidim} auf zwei Achsen.}
\label{fig:zerlegung}
\end{figure}
Abbildung~\ref{fig:zerlegung} zeigt die Zerlegung des Graphen im ein- und zweidimensionalen Fall. Repräsentiert wird der Graph durch eine Adjazenzmatrix. Das heißt, dass auf beiden Achsen die Knoten eingetragen sind und jeder Eintrag in der Matrix die Information speichert, ob eine Kante zwischen diesen Knoten existiert oder nicht.  Im eindimensionalen Fall heißt das, dass die Knoten, die auf der horizontalen Achse eingetragen sind, und alle zugehörigen Kanten, dargestellt durch die Spalten in der Matrix, unter den Prozessoren aufgeteilt werden. Ein Rahmen (\textit{frame}) spiegelt also wider, was in einem Prozessor abgespeichert wird. Im Gegensatz dazu wird bei der zweidimensionalen Zerlegung auch die vertikale Achse auf mehrere Prozessoren aufgeteilt, wodurch es, wie schon weiter oben erwähnt, der Fall ist, dass sich mehrere Prozessoren die gleiche Knotenmenge teilen, aber unterschiedliche Kanten zu diesen Knoten abspeichern beziehungsweise behandeln.\\
Ausgehend von der level-basierten sequentiellen Breitensuche, dargestellt durch Algorithmus~\ref{stacks}, und der eindimensionalen Zerlegung des Graphen, werden wir zwei Algorithmen zur parallelen Breitensuche abstrakt veranschaulichen. Grundlegender Unterschied dieser zwei Algorithmen ist die Synchronisation zwischen den Prozessoren, also welche Daten werden wie synchronisiert. Außerdem liegen Unterschiede darin, wieviel die Prozessoren über den Gesamtzustand des Systems wissen, also zum Beispiel ob Knoten, die anderen Prozessoren zugeordnet sind, bereits besucht wurden und deshalb im nächsten Level nicht mehr berücksichtigt werden müssen. Wichtig ist jedoch, dass beide Algorithmen mit einer 1D Zerlegung des Graphen arbeiten und als Ausgabe einen \textit{breath-first tree} haben müssen. Falls dieser \textit{breath-first tree} in einem Array abgespeichert ist, bezeichnen wir dieses Array auch als \textit{Parent Array}.  Dabei wollen wir festlegen, dass dieses \textit{Parent Array} am Ende des Algorithmus nicht unbedingt auf einem Prozessor liegen muss, sondern auf den arbeitenden Prozessoren verteilt sein kann. Details über die Implementierung und welche Auswirkungen diese Unterschiede auf die Laufzeit des Algorithmus haben, sind in Kapitel~\ref{sec:details} beziehungsweise Kapitel~\ref{sec:analyse} zu finden.
\subsection{Paralleler BFS mit Allreduce Kommunikation}
\label{sec:bfs_alltoall}
Die Idee hinter diesem Algorithmus war neben der eindimensionalen Zerlegung des Graphen und damit parallelen Abarbeitung der Levels, dass die Prozessoren mehr Informationen über die anderen Prozessoren haben und deren Knoten, was in diesem Algorithmus bei der Erstellung des \textit{Parent Array} zugute kommt. Bei vielen parallelen Algorithmen der Breitensuche, wie auch beim Algorithmus in Kapitel~\ref{sec:bfs_alltoall} ist es so, dass die Prozessoren nur Informationen über die lokal gespeicherten Knoten besitzen und anhand dieser Informationen Entscheidungen treffen müssen, wodurch es zu einen erhöhten Kommunikationsaufwand zwischen den Prozessoren kommen kann. Zum Beispiel ist es einem Prozessor, der die Nachbarn eines neu besuchten Knoten durchläuft, bei diesen Algorithmen nicht bekannt, ob ein Knoten, der nicht zu den lokalen gehört, bereits besucht wurde, da dies nur der Prozessor weiß, dem der Knoten zugeteilt ist. Deshalb muss jedes Mal bei einem für einen Prozessor fremden Knoten, zwischen den Prozessoren kommuniziert werden, ob dieser Knoten bereits in einem vorherigen Level besucht wurde.\\
Aufgrund dieser Tatsache wird bei unserem ersten Algorithmus eine Datenstruktur zwischen den Prozessoren synchron gehalten, die über alle Knoten des Graphen die Information besitzt, ob ein Knoten besucht wurde oder nicht. Falls wir uns also gerade im Level \(d\) befinden, weiß jeder Prozessor welche Knoten im Graphen bis einschließlich zum Level \(d-1\) besucht wurden. Dazu verwenden wir als Datenstruktur ein Array \lstinline{a[1..n]}, wie in Algorithmus~\ref{par_allvisited} ersichtlich, das zu jedem Knoten die Information speichert, ob dieser Knoten bisher besucht wurde oder nicht. Dies stellen wir durch Abspeichern der Werte 0 (\textit{false}) und 1 (\textit{true}) in \lstinline{a[k]} zu jedem Knoten \(k \in V(G)\) sicher. Da wir anhand dieser Datenstruktur nur wissen, welche Knoten bis einschließlich des letzten Levels besucht wurden, jedoch nicht, welche davon noch nicht von den zuständigen Prozessoren bearbeitet wurden (also im letzten Level neu besucht wurden), braucht jeder Prozessor noch ein zweites Array \lstinline{v[1..n/p]}, welches zu jedem lokalen Knoten abspeichert, 0 oder 1, ob dieser Knoten lokal behandelt wurde und damit auch die Nachbarn dieses Knoten besucht wurden. Dieses Array hat die Länge \lstinline{n/p}, da jeder Prozessor für \lstinline{n/p} Knoten verantwortlich ist. Dabei ist \lstinline{p} die Anzahl der zur Verfügung stehenden Prozessoren. Zu beachten ist auch, dass alle Prozessoren ein \textit{Parent Array} \lstinline{$\pi$} der Länge \(n\) besitzen. Falls also ein Knoten \(x\) ausgehend von Knoten \(y\) zum ersten Mal besucht wird, dann trägt der Prozessor, der für \(y\) verantwortlich ist, den Knoten \(y\) als Vater von \(x\) ein, also \lstinline{$\pi$[x] = y}, wobei es sich bei \lstinline{$\pi$}, um das auf dem Prozessor lokal gespeicherte \textit{Parent Array} handelt.
\begin{lstlisting}[caption={Die Prozedur \lstinline{PARALLEL-BFS-ALLREDUCE} wird von allen verfügbaren Prozessoren parallel aufgerufen. Nach jeder Abarbeitung eines Levels findet durch die \lstinline{ALLREDUCE} Operationen eine sogenannte Barrier-Synchronisation statt, bei der zwischen den Prozessoren ausgetauscht wird, ob es überhaupt einen neu besuchten Knoten gibt (\lstinline{isNewLevel}), beziehungsweise wird das Array \lstinline{a} synchronisiert.},label=par_allvisited]
$\textbf{PARALLEL-BFS-ALLREDUCE}$($G_{p}$,s)
	$\textbf{for}$ 0 $\leq$ i $<$ n $\textbf{do}$
		a[i] = 0
		$\pi$[i] = NIL
	$\textbf{for}$ 0 $\leq$ i $<$ n/p $\textbf{do}$
		v[i] = 0
	a[s] = 1
	isNewLevel = 1
	$\pi$[s] = s
	$\textbf{while}$ (isNewLevel == 1)
		isNewLevel = 0
		$a_{p}$ = a[n/$\textit{p}$*$\textit{rank}$+1..n/$\textit{p}$*($\textit{rank}$+1)]
		FS = $\textit{GETNEWVISITED}$($a_{p}$,v)
		$\textbf{for}$ each u $\in$ FS
			v[u] = 1
			$\textbf{for}$ each v $\in$ $G_{p}$.Adj[u]
				$\textbf{if}$ a[v] == 0
					a[v] = 1
					$\pi$[v] = u
					isNewLevel = 1
		ALLREDUCE(isNewLevel,OR)
		ALLREDUCE(a,OR)
	REDUCE($\pi$, MAX, $p_{0}$)
\end{lstlisting}
Um den Algorithmus besser zu strukturieren, verwenden wir das \textbf{BSP-Modell} (\textit{bulk synchronous parallel}), das eine Abstraktion eines Rechners mit physikalisch verteiltem Speicher darstellt, so wie von Rauber und Rünger in \cite{rauber} beschrieben. Grundlegend für dieses Modell ist, dass eine Berechnung (Ergebnis eines Algorithmus) aus einer Folge von \textbf{Superschritten} besteht. In jedem Superschritt führt jeder Prozessor lokale Berechnungen durch und am Ende findet eine Barrier-Synchronisation statt, die durch Kommunikationoperationen bewerkstelligt wird. Wichtig in diesem Modell ist jedoch, dass die Barrier-Synchronisation für alle Prozessoren zum gleichen Zeitpunkt stattfindet und dass die verschickten Daten erst im nächsten Superschritt verwendet werden.
\begin{figure}[h]
 	\centering
	\includegraphics[width=0.4\textwidth]{bsp}
 	\caption{Nach der Breitensuche ist der Graph in Levels unterteilt. Dies ist ersichtlich an den Distanzen, die in den Knoten eingezeichnet sind. Der graue Knoten entspricht einem nicht besuchten Knoten.}
	\label{fig:bsp}
\end{figure}
In Algorithmus~\ref{par_allvisited} wird in einem Superschritt ein Level bearbeitet und entspricht einer Iteration der \lstinline{$\textbf{while}$} Schleife von Zeile 10-22.  Jeder Prozessor führt innerhalb dieses Superschrittes seine lokalen Berechnungen durch, bis am Ende die Barrier-Synchronisation durch die \lstinline{ALLREDUCE} Operationen durchgeführt wird.\\
Jeder Prozessor ruft die Prozedur \lstinline{PARALLEL-BFS-ALLREDUCE} auf und hat als Eingabe einen Teilgraphen \lstinline{$G_{p}$} und den Startknoten \lstinline{s}. Beim Teilgraphen \lstinline{$G_{p}$} handelt es sich um den eindimensional zerlegten Graphen. Das heißt jeder Prozessor besitzt \(n/p\) Knoten und alle Kanten zu den zugehörigen \(n/p\) Knoten. Dabei können wir davon ausgehen, das der erste Prozessor die ersten \(n/p\) Knoten zugeteilt bekommt, der zweite die zweiten \(n/p\) Knoten und so weiter. Zu Beginn findet wie bei den vorherigen Algorithmen eine Initialisierung der Datenstrukturen und Variablen statt. Der Startknoten \lstinline{s} wird im Array \lstinline{a} gesetzt. Außerdem brauchen wir eine zusätzliche Variable \lstinline{isNewLevel}, die die Information speichert, ob im letzten Superschritt zumindest ein Knoten besucht wurde. Diese Variable ist notwendig, da die Prozessoren anhand der Informationen der Arrays \lstinline{a} und \lstinline{v} nur herausfinden können, ob ein lokaler Knoten neu besucht wurde, nicht aber ob ein Knoten eines anderen Prozessors neu besucht wurde. Diese Variable wird am Ende jedes Superschrittes synchronisiert und nimmt den Wert 0 in Zeile 21 an, falls kein neuer Knoten im letzten Superschritt hinzugekommen ist. In Zeile 12 wird durch \lstinline{a[n/$\textit{p}$*$\textit{rank}$+1..n/$\textit{p}$*($\textit{rank}$+1)]} der Teil vom Array \lstinline{a} herausgenommen, der die Knoten enthält, für die der jeweilige aufrufende Prozessor zuständig ist. Mithilfe dieses Ausschnitts \lstinline{$a_{p}$} und des Arrays \lstinline{v}, die jeweils eine Länge von \(n/p\) haben, können nun mit der Funktion \lstinline{GETNEWVISITED} die Knoten herausgefiltert werden, die im letzten Superschritt neu besucht worden sind. Die Abarbeitung der zu bearbeitenden Knoten ist sehr ähnlich zu Algorithmus~\ref{stacks}, außer dass zusätzlich die Variable \lstinline{isNewLevel} auf 1 gesetzt wird, sobald ein neuer Knoten besucht wird.\\
Am Ende des Algorithmus findet die Barrier-Synchonisation statt, die mittels \lstinline{ALLREDUCE} Operationen ausgeführt wird. Um die \lstinline{ALLREDUCE} Operation zu erklären, werden wir zuerst auf die Operation \lstinline{REDUCE} eingehen, da man sagen kann, dass \lstinline{ALLREDUCE} in gewissen Sinne eine Erweiterung dieser Operation ist. Bei \lstinline{REDUCE} handelt es sich um eine Akkumulationsoperation oder auch globale Reduktionsoperation, bei der jeder beteiltigte Prozess Daten zur Verfügung stellt, die mittels einer binären Operation verknüpft werden. Das Ergebnis erhält dann ein definierter Wurzelprozess. \lstinline{ALLREDUCE} ist eine Multi-Akkumulationsoperation, bei der man sagen kann, dass jeder beteiligte Prozess eine Einzelakkumulationsoperation ausführt. Einfach ausgedrückt stellt also jeder Prozess, was in unserem Fall ein Prozessor ist, ein Datum zur Verfügung, das heißt es gibt bei \(p\) Prozessoren \(p\) Daten. Diese Daten werden dann mit einer definierten binären Operation zu einem Datum verknüpft und an alle Prozessoren gesendet. Es erhalten somit alle Prozessoren das selbe Ergebnis.\\
Für die Barrier-Synchronisation in Algorithmus~\ref{par_allvisited} wird sowohl \lstinline{isNewLevel} als auch das Array \lstinline{a} synchronisiert. Es werden bei der \lstinline{ALLREDUCE} Operation von jedem Prozessor die Daten \lstinline{isNewLevel} beziehungsweise \lstinline{a} herangenommen und zu einem einzigen Datum verknüpft. Damit keine Information verloren geht, also eine gesetzte 1 entweder in \lstinline{isNewLevel} oder an einer bestimmten Position von \lstinline{a} auch durch die \lstinline{ALLREDUCE} Operation im Ergebnis gesetzt bleibt, kommt nur eine binäre Operation für die Verknüpfung in Frage, nämlich die Operation \lstinline{OR}.\\
Die Schleife von Zeile 10-22 bricht an dem Punkt ab, bei dem kein einziger neuer Knoten von einem Prozessor besucht wird, also die Variable \lstinline{isNewLevel} den Wert 0 annimmt. Da nun ein \textit{Parent Array} \lstinline{$\pi$} als Ergebnis vorhanden ist, dieses jedoch noch auf den einzelnen Prozessoren verteilt ist oder anders gesagt jeder Prozessor nur einen Teil des \textit{breadth-first trees} besitzt, wird dieses per \lstinline{REDUCE} Operation verknüpft und das Ergebnis an den Wurzelprozessor \lstinline{$p_{0}$} geliefert. Als binäre Verknüpfungsoperation haben wir \lstinline{MAX} gewählt, da es sein, dass es mehrere Väter zu einem bestimmten Knoten gibt und der Knoten gewählt wird, der die höhere Identifikationsnummer besitzt. Dieser Fall kann auftreten, wenn ein bestimmter Knoten im gleichen Level von mehrereren Vaterknoten zum ersten Mal besucht wird und diese Vaterknoten, wenn diese zu unterschiedlichen Prozessoren gehören, nicht wissen, dass dieser Knoten gleichzeitig auch von Knoten anderen Prozessoren besucht wird. Dadurch können sich mehrere Knoten als Vater zu denselben Knoten in unterschiedliche lokale Versionen von \lstinline{$\pi$} eintragen.
\subsection{BFS mit All-to-all Kommunikation}
\label{sec:bfs_alltoall}
\section{Implementierungsdetails}
\label{sec:details}
\subsection{Hybrid}
Diese Kombination ist deshalb möglich, da Rechner mit physikalisch verteiltem Speicher aus mehreren Verarbeitungseinheiten (Knoten) und einem Verbindungsnetzwerk bestehen. Ein Knoten ist dabei ein selbständige Einheit, die aus einem oder mehreren Prozessoren besteht. Unbedingt das pdf von dcc.fc.up.pt vewenden + Bilder!

\section{Analyse der Algorithmen und Versuchsergebnisse}
\label{sec:analyse}

\clearpage

\bibliographystyle{abbrv}
\bibliography{bachelor}
\clearpage
\appendix
\section{BFS versions}
\label{sec:versions}
\lstinputlisting[firstline=138,lastline=196,caption={Version 1 - level bitmap},label=version1]{../Source/bfs_par.c}
\lstinputlisting[firstline=135,lastline=183,caption={Version 2 - level array},label=version2]{../Source/bfs_par_parentarray.c}
\lstinputlisting[firstline=153,lastline=205,caption={Version 3 - visited bitmap},label=version3]{../Source/bfs_par_allvisited_parallelsort.c}
\section{Source Code - graph500}
\label{sec:sourcecode}
\lstinputlisting[caption={BFS solution},label=bfs]{../Source/bfs_par_allvisited_parallelsort.c}
\clearpage
\lstinputlisting[caption={Kronecker Generator},label=kronecker_generator]{../Source/kronecker_generator.c}
\clearpage
\lstinputlisting[caption={project.h},label=project]{../Source/project.h}

\clearpage


\end{document}